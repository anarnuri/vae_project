{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm \n",
    "from vae import VAE\n",
    "import torch\n",
    "import cv2\n",
    "import json \n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "# Get the current date in monthdayyear format\n",
    "date = datetime.now().strftime('%m%d%Y')\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "latent_dim = 10\n",
    "\n",
    "checkpoint_path = f\"./weights/lat_{latent_dim}.ckpt\"\n",
    "checkpoint = torch.load(checkpoint_path)\n",
    "model = VAE(latent_dim).eval().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from string \n",
    "def process_string_mech(dir, toNpy = True):\n",
    "    # I do not know why but this works for windows os. You may need to change this if you are using linux/macbook\n",
    "    # Zhijie: you can test using strings like: \n",
    "    # ./outputs-4bar/-0.001 2.728 5.504 -1.565 -5.632 -2.481 -8.711 9.682 1.320 -5.630 -7.171 3.601 RRRP  0.42 0.026 0.732 -0.026 0.42 2.011 0. 0. 1. .jpg\n",
    "    input_string = dir.split('\\\\')[-1].split('.j')[0] \n",
    "    \n",
    "    # Split the string by spaces\n",
    "    parts = input_string.split()\n",
    "    \n",
    "    # Initialize lists to hold floats\n",
    "    floats_before = []\n",
    "    floats_after = []\n",
    "    letter_string = None\n",
    "    \n",
    "    # Iterate over parts to separate floats and the letter string\n",
    "    for part in parts:\n",
    "        try:\n",
    "            # Try to convert part to float\n",
    "            num = float(part)\n",
    "            # Add to floats_before if letter_string is not yet found\n",
    "            if letter_string is None:\n",
    "                floats_before.append(num)\n",
    "            else:\n",
    "                floats_after.append(num)\n",
    "        except ValueError:\n",
    "            # If conversion fails, this part is the letter string\n",
    "            letter_string = part\n",
    "    \n",
    "    if toNpy:\n",
    "        floats_before = np.array(floats_before).reshape((-1, 2))\n",
    "        floats_after = np.matrix(floats_after).reshape((3, 3))\n",
    "    \n",
    "    return floats_before, letter_string, floats_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BSIdictionary update (PRPR)\n",
    "file_path = './KV_468.json'\n",
    "\n",
    "# Open and read the JSON file\n",
    "with open(file_path, 'r') as file:\n",
    "    KVdict = json.load(file) \n",
    "\n",
    "image_folder = './outputs-6bar/'\n",
    "\n",
    "six_bar  = ['Watt1T1A1', 'Watt1T2A1', 'Watt1T3A1', 'Watt1T1A2', 'Watt1T2A2', 'Watt1T3A2', \n",
    "            'Watt2T1A1', 'Watt2T2A1', 'Watt2T1A2', 'Watt2T2A2', 'Steph1T1', 'Steph1T2',\n",
    "            'Steph1T3', 'Steph2T1A1', 'Steph2T2A1', 'Steph2T2A2', 'Steph3T1A1', 'Steph3T2A1', \n",
    "            'Steph3T1A2', 'Steph3T2A2', 'Steph2T1A2']\n",
    "\n",
    "z_folder = './outputs-z/'\n",
    "e_folder = './outputs-encoded/'\n",
    "\n",
    "os.makedirs(z_folder, exist_ok=True)\n",
    "os.makedirs(e_folder, exist_ok=True)\n",
    "\n",
    "setSize = 3000 # len(imgStrings) # determine how many samples for each type. \n",
    "batchSize = 1000\n",
    "\n",
    "for mechType in six_bar:\n",
    "    batchImg = []\n",
    "    result_zSet = []\n",
    "    result_featSet = []\n",
    "    value = KVdict[mechType]\n",
    "    imgStrings = glob(image_folder + mechType + '/*')\n",
    "    for i in tqdm(range(min(setSize, len(imgStrings)))): \n",
    "        batchImg.append(cv2.imread(imgStrings[i], cv2.IMREAD_GRAYSCALE)/ 255) # This /255 works better than not doing it \n",
    "        floats_before, letter_string, floats_after = process_string_mech(imgStrings[i], toNpy = False)\n",
    "        if len(floats_after) == 6:\n",
    "            floats_after = floats_after + [0, 0, 1]\n",
    "        elif len(floats_after) != 9: \n",
    "            break\n",
    "        result_featSet.append(np.array(floats_before + [KVdict[letter_string]] + floats_after, dtype= float).flatten().tolist())\n",
    "        if len(batchImg) >= batchSize:\n",
    "            images = torch.from_numpy(np.array([batchImg])).swapaxes(0,1).float().to(device)\n",
    "            x = model.encoder(images)\n",
    "            mean, logvar = x[:, : model.latent_dim], x[:, model.latent_dim :]\n",
    "            z = model.reparameterize(mean, logvar)\n",
    "            z = z.cpu().detach().numpy()\n",
    "            result_zSet.append(z)\n",
    "            batchImg = []\n",
    "\n",
    "    if len(batchImg) > 0:\n",
    "        images = torch.from_numpy(np.array([batchImg])).swapaxes(0,1).float().to(device)\n",
    "        x = model.encoder(images)\n",
    "        mean, logvar = x[:, : model.latent_dim], x[:, model.latent_dim :]\n",
    "        z = model.reparameterize(mean, logvar)\n",
    "        z = z.cpu().detach().numpy()\n",
    "        result_zSet.append(z)\n",
    "        batchImg = []\n",
    "\n",
    "    result_zSet = np.concatenate(result_zSet)\n",
    "\n",
    "    batchZname = z_folder + date + '-z-' + str(int(KVdict[mechType]))\n",
    "    batchEname = e_folder + date + '-encoded-' + str(int(KVdict[mechType]))\n",
    "    np.save(batchZname, np.array(result_zSet))\n",
    "    np.save(batchEname, np.array(result_featSet))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
